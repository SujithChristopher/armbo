{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import msgpack as mp\n",
    "import msgpack_numpy as mpn\n",
    "import toml\n",
    "import cv2\n",
    "from cv2 import aruco\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORMAT: SEGMENTATION, CLASSIFICATION, POSE\n",
    "# TODO: remove combining of all data\n",
    "DATASET_FORMAT = \"POSE\"\n",
    "RECORDING_TYPE = \"MULTIVIDEO\"\n",
    "FILTER_BASED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the parameter.toml for different directory\n",
    "Defining folders and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pth = r\"F:\\greenscreen_dataset\"\n",
    "_f = toml.load(os.path.join(os.path.dirname(os.getcwd()), \"parameters.toml\"))[\n",
    "    \"raw_dataset\"\n",
    "][\"pth\"]\n",
    "process_file = os.listdir(_f)[os.listdir(_f).index(\"00_analysis\")]\n",
    "# analysis_folder = os.path.join(data_pth, process_file)\n",
    "# analysis_file = os.path.join(analysis_folder, 'folder_names.txt')\n",
    "\n",
    "training_pth = toml.load(os.path.join(os.path.dirname(os.getcwd()), \"parameters.toml\"))[\n",
    "    \"training_dataset\"\n",
    "][\"pth\"]\n",
    "training_raw_data = os.path.join(training_pth, \"raw_data_2\")\n",
    "\n",
    "if not os.path.exists(training_raw_data):\n",
    "    os.mkdir(training_raw_data)\n",
    "    os.mkdir(os.path.join(training_raw_data, \"labels\"))\n",
    "    os.mkdir(os.path.join(training_raw_data, \"images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00_analysis'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_folders_list = os.listdir(os.path.join(data_pth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.mov', '2.mov', '3.mov', '4.mov', '5.mov']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_folders_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration files path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[671.25534529,   0.        , 678.00736213],\n",
       "       [  0.        , 692.23316717, 443.37269229],\n",
       "       [  0.        ,   0.        ,   1.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_calib_folder_name = \"calibration_00\"\n",
    "_webcam_calib_pth = os.path.join(\n",
    "    _f, os.path.dirname(process_file), _calib_folder_name, \"webcam_calibration.msgpack\"\n",
    ")\n",
    "\n",
    "with open(_webcam_calib_pth, \"rb\") as f:\n",
    "    webcam_calib = mp.Unpacker(f, object_hook=mpn.decode)\n",
    "    _temp = next(webcam_calib)\n",
    "    _webcam_cam_mat = _temp[0]\n",
    "    _webcam_dist = _temp[1]\n",
    "\n",
    "_webcam_cam_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArUco dictionary and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_size = 0.05\n",
    "\n",
    "marker_points = np.array(\n",
    "    [\n",
    "        [-marker_size / 2, marker_size / 2, 0],\n",
    "        [marker_size / 2, marker_size / 2, 0],\n",
    "        [marker_size / 2, -marker_size / 2, 0],\n",
    "        [-marker_size / 2, -marker_size / 2, 0],\n",
    "    ],\n",
    "    dtype=np.float32,\n",
    ")\n",
    "\n",
    "ARUCO_PARAMETERS = aruco.DetectorParameters()\n",
    "ARUCO_DICT = aruco.getPredefinedDictionary(aruco.DICT_ARUCO_MIP_36H12)\n",
    "detector = aruco.ArucoDetector(ARUCO_DICT, ARUCO_PARAMETERS)\n",
    "markerLength = marker_size\n",
    "markerSeperation = 0.01\n",
    "\n",
    "board = aruco.GridBoard(\n",
    "    size=[1, 1],\n",
    "    markerLength=markerLength,\n",
    "    markerSeparation=markerSeperation,\n",
    "    dictionary=ARUCO_DICT,\n",
    ")\n",
    "\n",
    "\n",
    "def my_estimatePoseSingleMarkers(corners, marker_points, mtx, distortion):\n",
    "    trash = []\n",
    "    rvecs = []\n",
    "    tvecs = []\n",
    "    for c in corners:\n",
    "        nada, R, t = cv2.solvePnP(\n",
    "            marker_points, c, mtx, distortion, False, flags=cv2.SOLVEPNP_ITERATIVE\n",
    "        )\n",
    "        R = R.T\n",
    "        t = t.T\n",
    "        rvecs.append(R)\n",
    "        tvecs.append(t)\n",
    "        trash.append(nada)\n",
    "    return rvecs, tvecs, trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\greenscreen_dataset\\1.mov\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:14<00:56, 14.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\greenscreen_dataset\\2.mov\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:27<00:40, 13.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\greenscreen_dataset\\3.mov\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:41<00:27, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\greenscreen_dataset\\4.mov\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:54<00:13, 13.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\greenscreen_dataset\\5.mov\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:09<00:00, 13.86s/it]\n"
     ]
    }
   ],
   "source": [
    "default_ids = [12, 88, 89]\n",
    "data = {\"frame_id\": [], \"marker_ids\": [], \"corners\": [], \"tvec\": [], \"rvec\": []}\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for _name in tqdm(video_folders_list):\n",
    "    _video_path = os.path.join(data_pth, os.path.dirname(process_file), _name)\n",
    "    print(_video_path)\n",
    "    _video_file = cv2.VideoCapture(_video_path)\n",
    "    # _video_file = mp.Unpacker(open(_video_path, \"rb\"), object_hook=mpn.decode)\n",
    "    detector = aruco.ArucoDetector(ARUCO_DICT, ARUCO_PARAMETERS)\n",
    "\n",
    "    while _video_file.isOpened():\n",
    "        ret, frame = _video_file.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        corners, ids, rejectedImgPoints = detector.detectMarkers(gray)\n",
    "        corners, ids, rejectedImgPoints, _ = detector.refineDetectedMarkers(\n",
    "            image=gray,\n",
    "            board=board,\n",
    "            detectedCorners=corners,\n",
    "            detectedIds=ids,\n",
    "            rejectedCorners=rejectedImgPoints,\n",
    "            cameraMatrix=_webcam_cam_mat,\n",
    "            distCoeffs=_webcam_dist,\n",
    "        )\n",
    "        if ids is None:\n",
    "            data[\"frame_id\"].append(counter)\n",
    "            data[\"marker_ids\"].append(ids)\n",
    "            data[\"corners\"].append(corners)\n",
    "            data[\"tvec\"].append(None)\n",
    "            data[\"rvec\"].append(None)\n",
    "        if ids is not None:\n",
    "            data[\"frame_id\"].append(counter)\n",
    "            data[\"marker_ids\"].append(ids)\n",
    "            data[\"corners\"].append(corners)\n",
    "\n",
    "            rotation_vectors, translation_vectors, _ = my_estimatePoseSingleMarkers(\n",
    "                corners, marker_points, _webcam_cam_mat, _webcam_dist\n",
    "            )\n",
    "            data[\"tvec\"].append(translation_vectors)\n",
    "            data[\"rvec\"].append(rotation_vectors)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate = {\n",
    "    str(default_ids[0]): {\"x\": [], \"y\": [], \"z\": [], \"rx\": [], \"ry\": [], \"rz\": []},\n",
    "    str(default_ids[1]): {\"x\": [], \"y\": [], \"z\": [], \"rx\": [], \"ry\": [], \"rz\": []},\n",
    "    str(default_ids[2]): {\"x\": [], \"y\": [], \"z\": [], \"rx\": [], \"ry\": [], \"rz\": []},\n",
    "}\n",
    "\n",
    "doesnt_exist = []  # list of ids that doesnt exist in a frame\n",
    "\n",
    "for i in range(len(data[\"frame_id\"])):\n",
    "    if data[\"marker_ids\"][i] is not None:\n",
    "        if default_ids[0] not in data[\"marker_ids\"][i]:\n",
    "            doesnt_exist.append(default_ids[0])\n",
    "        if default_ids[1] not in data[\"marker_ids\"][i]:\n",
    "            doesnt_exist.append(default_ids[1])\n",
    "        if default_ids[2] not in data[\"marker_ids\"][i]:\n",
    "            doesnt_exist.append(default_ids[2])\n",
    "\n",
    "        for j in range(len(data[\"marker_ids\"][i])):\n",
    "            if data[\"marker_ids\"][i][j] in default_ids:\n",
    "                coordinate[str(data[\"marker_ids\"][i][j][0])][\"x\"].append(\n",
    "                    data[\"tvec\"][i][j][0][0]\n",
    "                )\n",
    "                coordinate[str(data[\"marker_ids\"][i][j][0])][\"y\"].append(\n",
    "                    data[\"tvec\"][i][j][0][1]\n",
    "                )\n",
    "                coordinate[str(data[\"marker_ids\"][i][j][0])][\"z\"].append(\n",
    "                    data[\"tvec\"][i][j][0][2]\n",
    "                )\n",
    "                coordinate[str(data[\"marker_ids\"][i][j][0])][\"rx\"].append(\n",
    "                    data[\"rvec\"][i][j][0][0]\n",
    "                )\n",
    "                coordinate[str(data[\"marker_ids\"][i][j][0])][\"ry\"].append(\n",
    "                    data[\"rvec\"][i][j][0][1]\n",
    "                )\n",
    "                coordinate[str(data[\"marker_ids\"][i][j][0])][\"rz\"].append(\n",
    "                    data[\"rvec\"][i][j][0][2]\n",
    "                )\n",
    "        for k in doesnt_exist:\n",
    "            coordinate[str(k)][\"x\"].append(np.nan)\n",
    "            coordinate[str(k)][\"y\"].append(np.nan)\n",
    "            coordinate[str(k)][\"z\"].append(np.nan)\n",
    "            coordinate[str(k)][\"rx\"].append(np.nan)\n",
    "            coordinate[str(k)][\"ry\"].append(np.nan)\n",
    "            coordinate[str(k)][\"rz\"].append(np.nan)\n",
    "        doesnt_exist = []\n",
    "    else:\n",
    "        for k in default_ids:\n",
    "            coordinate[str(k)][\"x\"].append(np.nan)\n",
    "            coordinate[str(k)][\"y\"].append(np.nan)\n",
    "            coordinate[str(k)][\"z\"].append(np.nan)\n",
    "            coordinate[str(k)][\"rx\"].append(np.nan)\n",
    "            coordinate[str(k)][\"ry\"].append(np.nan)\n",
    "            coordinate[str(k)][\"rz\"].append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_df_12 = pd.DataFrame(coordinate[\"12\"])\n",
    "ar_df_12[\"sort\"] = ar_df_12[\"z\"].diff() > 1\n",
    "drop_idx_12 = ar_df_12.query(\"sort == True\").index\n",
    "\n",
    "ar_df_88 = pd.DataFrame(coordinate[\"88\"])\n",
    "ar_df_88[\"sort\"] = ar_df_88[\"z\"].diff() > 1\n",
    "drop_idx_88 = ar_df_88.query(\"sort == True\").index\n",
    "\n",
    "ar_df_89 = pd.DataFrame(coordinate[\"89\"])\n",
    "ar_df_89[\"sort\"] = ar_df_89[\"z\"].diff() > 1\n",
    "drop_idx_89 = ar_df_89.query(\"sort == True\").index\n",
    "\n",
    "drop_ids = []\n",
    "for i in drop_idx_12:\n",
    "    drop_ids.append(i)\n",
    "for i in drop_idx_88:\n",
    "    drop_ids.append(i)\n",
    "for i in drop_idx_89:\n",
    "    drop_ids.append(i)\n",
    "drop = {\"drop\": drop_ids}\n",
    "drop_ids = pl.DataFrame(drop)\n",
    "drops = drop_ids[\"drop\"].unique().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [03:38<00:00, 43.71s/it]\n"
     ]
    }
   ],
   "source": [
    "default_ids = [12, 88, 89]\n",
    "data = {\"frame_id\": [], \"marker_ids\": [], \"corners\": [], \"tvec\": [], \"rvec\": []}\n",
    "\n",
    "counter = len(os.listdir(r\"E:\\toTrain\\raw_data\\images\")) + 1\n",
    "second_counter = 0\n",
    "\n",
    "for _name in tqdm(video_folders_list):\n",
    "    _video_path = os.path.join(data_pth, os.path.dirname(process_file), _name)\n",
    "    _video_file = cv2.VideoCapture(_video_path)\n",
    "    # _video_file = mp.Unpacker(open(_video_path, \"rb\"), object_hook=mpn.decode)\n",
    "    detector = aruco.ArucoDetector(ARUCO_DICT, ARUCO_PARAMETERS)\n",
    "\n",
    "    while _video_file.isOpened():\n",
    "        ret, _frame = _video_file.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        height, width = _frame.shape[:2]\n",
    "        gray = cv2.cvtColor(_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        markerCorners, ids, rejectedImgPoints = detector.detectMarkers(gray)\n",
    "\n",
    "        markerCorners, ids, rejectedImgPoints, _ = detector.refineDetectedMarkers(\n",
    "            image=gray,\n",
    "            board=board,\n",
    "            detectedCorners=markerCorners,\n",
    "            detectedIds=ids,\n",
    "            rejectedCorners=rejectedImgPoints,\n",
    "            cameraMatrix=_webcam_cam_mat,\n",
    "            distCoeffs=_webcam_dist,\n",
    "        )\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        if counter in drops:\n",
    "            continue\n",
    "\n",
    "        second_counter += 1\n",
    "\n",
    "        img_name = f\"image_{counter}.png\"\n",
    "\n",
    "        label_name = img_name.split(\".\")[0]\n",
    "        label_path = os.path.join(training_raw_data, \"labels\", f\"{label_name}.txt\")\n",
    "        label_file = open(label_path, \"w\", newline=\"\")\n",
    "        label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "\n",
    "        _class_name = \"\"\n",
    "\n",
    "        for i in range(len(ids)):\n",
    "            _markerCorners = markerCorners[i][0]\n",
    "            bbox_x, bbox_y, bbox_width, bbox_height = cv2.boundingRect(_markerCorners)\n",
    "\n",
    "            bbox_x = bbox_x / width\n",
    "            bbox_y = bbox_y / height\n",
    "\n",
    "            bbox_center_x = bbox_x + bbox_width / (2 * width)\n",
    "            bbox_center_y = bbox_y + bbox_height / (2 * height)\n",
    "\n",
    "            bbox_width = bbox_width / width\n",
    "            bbox_height = bbox_height / height\n",
    "            if ids[i][0] == default_ids[0]:\n",
    "                _class_name = \"0\"\n",
    "            elif ids[i][0] == default_ids[1]:\n",
    "                _class_name = \"1\"\n",
    "            elif ids[i][0] == default_ids[2]:\n",
    "                _class_name = \"2\"\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if DATASET_FORMAT == \"SEGMENTATION\":\n",
    "                label_writer.writerow(\n",
    "                    [\n",
    "                        _class_name,\n",
    "                        _markerCorners[0][0] / width,\n",
    "                        _markerCorners[0][1] / height,\n",
    "                        _markerCorners[1][0] / width,\n",
    "                        _markerCorners[1][1] / height,\n",
    "                        _markerCorners[2][0] / width,\n",
    "                        _markerCorners[2][1] / height,\n",
    "                        _markerCorners[3][0] / width,\n",
    "                        _markerCorners[3][1] / height,\n",
    "                        _markerCorners[0][0] / width,\n",
    "                        _markerCorners[0][1] / height,\n",
    "                    ]\n",
    "                )\n",
    "            elif DATASET_FORMAT == \"POSE\":\n",
    "                label_writer.writerow(\n",
    "                    [\n",
    "                        _class_name,\n",
    "                        bbox_center_x,\n",
    "                        bbox_center_y,\n",
    "                        bbox_width,\n",
    "                        bbox_height,\n",
    "                        _markerCorners[0][0] / width,\n",
    "                        _markerCorners[0][1] / height,\n",
    "                        _markerCorners[1][0] / width,\n",
    "                        _markerCorners[1][1] / height,\n",
    "                        _markerCorners[2][0] / width,\n",
    "                        _markerCorners[2][1] / height,\n",
    "                        _markerCorners[3][0] / width,\n",
    "                        _markerCorners[3][1] / height,\n",
    "                        _markerCorners[0][0] / width,\n",
    "                        _markerCorners[0][1] / height,\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        label_file.close()\n",
    "        image_path = os.path.join(training_raw_data, \"images\", img_name)\n",
    "        cv2.imwrite(image_path, _frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\\\\\toTrain\\\\raw_data'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12573, 12572)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter, second_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding gaussian blur and salt and pepper noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processes = 20  # You can adjust this based on your requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=20)]: Done 410 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=20)]: Done 760 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=20)]: Done 1210 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=20)]: Done 1820 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=20)]: Done 3120 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=20)]: Done 4620 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=20)]: Done 6320 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=20)]: Done 8220 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=20)]: Done 10320 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=20)]: Done 12533 out of 12572 | elapsed:  2.7min remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done 12572 out of 12572 | elapsed:  2.7min finished\n"
     ]
    }
   ],
   "source": [
    "_raw_saved_data_pth = os.path.join(training_raw_data, \"images\")\n",
    "_raw_saved_data_list = os.listdir(os.path.join(training_raw_data, \"images\"))\n",
    "\n",
    "\n",
    "def add_noise(image):\n",
    "    img = image[..., ::-1] / 255.0\n",
    "    noise = np.random.normal(loc=0, scale=1, size=img.shape)\n",
    "    noisy2 = np.clip((img + noise * 0.4), 0, 1)\n",
    "    noisy2 = (noisy2 * 255).astype(np.uint8)\n",
    "    noisy2 = noisy2[..., ::-1]\n",
    "    return noisy2\n",
    "\n",
    "\n",
    "def gaussian_blur(image):\n",
    "    return cv2.GaussianBlur(image, (3, 35), 0)\n",
    "\n",
    "\n",
    "def adding_noise_to_image(img_name):\n",
    "    _image_path = os.path.join(_raw_saved_data_pth, img_name)\n",
    "    image = cv2.imread(_image_path)\n",
    "    # adding noise to twenty percent of the images\n",
    "    _csv_rows = []\n",
    "    if np.random.random() < 0.4:\n",
    "        image = gaussian_blur(image)\n",
    "        _image_path = os.path.join(_raw_saved_data_pth, f\"blur_{img_name}\")\n",
    "        cv2.imwrite(_image_path, image)\n",
    "\n",
    "        label_name = img_name.split(\".\")[0]\n",
    "        label_path = os.path.join(\n",
    "            _raw_saved_data_pth, \"..\", \"labels\", f\"{label_name}.txt\"\n",
    "        )\n",
    "        label_file = open(label_path, \"r\", newline=\"\")\n",
    "        label_reader = csv.reader(label_file, delimiter=\" \")\n",
    "        for _row in label_reader:\n",
    "            _csv_rows.append(_row)\n",
    "        label_file.close()\n",
    "\n",
    "        label_path = os.path.join(\n",
    "            os.path.join(_raw_saved_data_pth, \"..\", \"labels\"),\n",
    "            f\"blur_{img_name.split('.')[0]}.txt\",\n",
    "        )\n",
    "        label_file = open(label_path, \"w\", newline=\"\")\n",
    "        label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "        for _r in _csv_rows:\n",
    "            label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "            label_writer.writerow(_r)\n",
    "\n",
    "        _csv_rows.clear()\n",
    "        label_file.close()\n",
    "\n",
    "    if np.random.random() > 0.3 and np.random.random() < 0.6:\n",
    "        image = add_noise(image)\n",
    "        _image_path = os.path.join(_raw_saved_data_pth, f\"noise_{img_name}\")\n",
    "        cv2.imwrite(_image_path, image)\n",
    "\n",
    "        label_name = img_name.split(\".\")[0]\n",
    "        label_path = os.path.join(\n",
    "            _raw_saved_data_pth, \"..\", \"labels\", f\"{label_name}.txt\"\n",
    "        )\n",
    "        label_file = open(label_path, \"r\", newline=\"\")\n",
    "        label_reader = csv.reader(label_file, delimiter=\" \")\n",
    "        for _row in label_reader:\n",
    "            _csv_rows.append(_row)\n",
    "        label_file.close()\n",
    "\n",
    "        label_path = os.path.join(\n",
    "            os.path.join(_raw_saved_data_pth, \"..\", \"labels\"),\n",
    "            f\"noise_{img_name.split('.')[0]}.txt\",\n",
    "        )\n",
    "        label_file = open(label_path, \"w\", newline=\"\")\n",
    "        label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "        for _r in _csv_rows:\n",
    "            label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "            label_writer.writerow(_r)\n",
    "\n",
    "        _csv_rows.clear()\n",
    "        label_file.close()\n",
    "    return 0\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=num_processes, verbose=1)(\n",
    "    delayed(adding_noise_to_image)(element) for element in _raw_saved_data_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_pth = r\"E:\\toTrain\\raw_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\CMC\\\\pyprojects\\\\DeepVision'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pth = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "data_pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done 200 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=20)]: Done 700 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=20)]: Done 1400 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=20)]: Done 2300 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=20)]: Done 3400 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=20)]: Done 4700 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=20)]: Done 6200 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=20)]: Done 7900 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=20)]: Done 9800 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=20)]: Done 11570 tasks      | elapsed:   56.2s\n",
      "[Parallel(n_jobs=20)]: Done 13300 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=20)]: Done 15800 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=20)]: Done 18500 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=20)]: Done 21400 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=20)]: Done 24500 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=20)]: Done 25565 out of 25604 | elapsed:  2.3min remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 25604 out of 25604 | elapsed:  2.3min finished\n"
     ]
    }
   ],
   "source": [
    "# splitting dataset into train and validation and test\n",
    "# data_pth = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "# data_pth = os.path.join(data_pth, 'dataset',\"multi_class\", \"dataset_processed\")\n",
    "data_pth = r\"F:\\dataset_processed_v3\"\n",
    "\n",
    "images_pth = os.path.join(data_pth, \"images\")\n",
    "labels_pth = os.path.join(data_pth, \"labels\")\n",
    "\n",
    "if not os.path.exists(images_pth):\n",
    "    os.makedirs(os.path.join(images_pth, \"train\"))\n",
    "    os.makedirs(os.path.join(images_pth, \"val\"))\n",
    "    os.makedirs(os.path.join(images_pth, \"test\"))\n",
    "\n",
    "if not os.path.exists(labels_pth):\n",
    "    os.makedirs(os.path.join(labels_pth, \"train\"))\n",
    "    os.makedirs(os.path.join(labels_pth, \"val\"))\n",
    "    os.makedirs(os.path.join(labels_pth, \"test\"))\n",
    "\n",
    "\n",
    "image_list = os.listdir(os.path.join(raw_data_pth, \"images\"))\n",
    "\n",
    "\n",
    "def split_dataset(img_name):\n",
    "    _image_path = os.path.join(raw_data_pth, \"images\", img_name)\n",
    "    image = cv2.imread(_image_path)\n",
    "\n",
    "    label_name = img_name.split(\".\")[0]\n",
    "    label_path = os.path.join(raw_data_pth, \"labels\", f\"{label_name}.txt\")\n",
    "    label_file = open(label_path, \"r\", newline=\"\")\n",
    "    label_reader = csv.reader(label_file, delimiter=\" \")\n",
    "\n",
    "    label = []\n",
    "    for l in label_reader:\n",
    "        label.append(l)\n",
    "\n",
    "    label_file.close()\n",
    "\n",
    "    # if int(label[0]) == 0:\n",
    "    if np.random.rand() < 0.7:\n",
    "        # save image\n",
    "        image_path = os.path.join(os.path.join(images_pth, \"train\"), img_name)\n",
    "        cv2.imwrite(image_path, image)\n",
    "\n",
    "        label_path = os.path.join(\n",
    "            os.path.join(labels_pth, \"train\"), f\"{label_name}.txt\"\n",
    "        )\n",
    "        label_file = open(label_path, \"w\", newline=\"\")\n",
    "        label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "        for l in label:\n",
    "            label_writer.writerow(l)\n",
    "        label_file.close()\n",
    "\n",
    "    elif np.random.rand() < 0.9 and np.random.rand() > 0.7:\n",
    "        # save image\n",
    "        image_path = os.path.join(os.path.join(images_pth, \"val\"), img_name)\n",
    "        cv2.imwrite(image_path, image)\n",
    "\n",
    "        label_path = os.path.join(os.path.join(labels_pth, \"val\"), f\"{label_name}.txt\")\n",
    "        label_file = open(label_path, \"w\", newline=\"\")\n",
    "        label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "        for l in label:\n",
    "            label_writer.writerow(l)\n",
    "        label_file.close()\n",
    "\n",
    "    else:\n",
    "        # save image\n",
    "        image_path = os.path.join(os.path.join(images_pth, \"test\"), img_name)\n",
    "        cv2.imwrite(image_path, image)\n",
    "\n",
    "        label_path = os.path.join(os.path.join(labels_pth, \"test\"), f\"{label_name}.txt\")\n",
    "        label_file = open(label_path, \"w\", newline=\"\")\n",
    "        label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "        for l in label:\n",
    "            label_writer.writerow(l)\n",
    "        label_file.close()\n",
    "\n",
    "    label.clear()\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=num_processes, verbose=1)(\n",
    "    delayed(split_dataset)(element) for element in image_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py115",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
