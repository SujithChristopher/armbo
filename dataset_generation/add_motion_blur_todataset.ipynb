{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import aruco\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import msgpack as mp\n",
    "import msgpack_numpy as mpn\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import toml\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_parameters = [4, 6, 8, 10]\n",
    "angle_parameters = [0, 30, 60, 90, 120, 150, 180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processes = 20  # You can adjust this based on your requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pth = toml.load(os.path.join(os.path.dirname(os.getcwd()), \"parameters.toml\"))[\n",
    "    \"training_dataset\"\n",
    "][\"pth\"]\n",
    "training_raw_data = os.path.join(training_pth, \"raw_data\")\n",
    "_raw_saved_data_pth = training_raw_data\n",
    "_raw_saved_data_list = os.listdir(os.path.join(training_raw_data, \"images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_raw_saved_data_list = list(\n",
    "    filter(lambda x: x.split(\"_\")[0] != \"blur\", _raw_saved_data_list)\n",
    ")\n",
    "_raw_saved_data_list = list(\n",
    "    filter(lambda x: x.split(\"_\")[0] != \"noise\", _raw_saved_data_list)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _blur_save_pth = os.path.dirname(os.path.dirname(_raw_saved_data_pth))\n",
    "# _blur_save_pth = os.path.join(_blur_save_pth, 'motion_blur')\n",
    "_blur_save_img_pth = os.path.join(_raw_saved_data_pth, \"images\")\n",
    "_blur_save_label_pth = os.path.join(_raw_saved_data_pth, \"labels\")\n",
    "\n",
    "if not os.path.exists(_blur_save_img_pth):\n",
    "    os.makedirs(_blur_save_img_pth)\n",
    "\n",
    "if not os.path.exists(_blur_save_label_pth):\n",
    "    os.makedirs(_blur_save_label_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_motion_blur(image, size, angle):\n",
    "    k = np.zeros((size, size), dtype=np.float32)\n",
    "    k[(size - 1) // 2, :] = np.ones(size, dtype=np.float32)\n",
    "    k = cv2.warpAffine(\n",
    "        k,\n",
    "        cv2.getRotationMatrix2D((size / 2 - 0.5, size / 2 - 0.5), angle, 1.0),\n",
    "        (size, size),\n",
    "    )\n",
    "    k = k * (1.0 / np.sum(k))\n",
    "    return cv2.filter2D(image, -1, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=20)]: Done 260 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=20)]: Done 1260 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=20)]: Done 1991 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=20)]: Done 2880 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=20)]: Done 3980 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=20)]: Done 5280 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=20)]: Done 6780 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=20)]: Done 8480 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=20)]: Done 10380 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=20)]: Done 12480 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=20)]: Done 12533 out of 12572 | elapsed:  2.0min remaining:    0.3s\n",
      "[Parallel(n_jobs=20)]: Done 12572 out of 12572 | elapsed:  2.0min finished\n"
     ]
    }
   ],
   "source": [
    "def adding_blur_to_image(img_name):\n",
    "    _image_path = os.path.join(_raw_saved_data_pth, \"images\", img_name)\n",
    "    image = cv2.imread(_image_path)\n",
    "    # adding noise to twenty percent of the images\n",
    "    _csv_rows = []\n",
    "\n",
    "    if np.random.random() < 0.15:\n",
    "        for _b in blur_parameters:\n",
    "            for _a in angle_parameters:\n",
    "                _blur_size = _b\n",
    "                _blur_angle = _a\n",
    "\n",
    "                image = apply_motion_blur(image, _blur_size, _blur_angle)\n",
    "\n",
    "                _image_path = os.path.join(\n",
    "                    _blur_save_img_pth, f\"blur_s{_blur_size}_a{_blur_angle}_{img_name}\"\n",
    "                )\n",
    "                cv2.imwrite(_image_path, image)\n",
    "\n",
    "                label_name = img_name.split(\".\")[0]\n",
    "                label_path = os.path.join(\n",
    "                    _raw_saved_data_pth, \"labels\", f\"{label_name}.txt\"\n",
    "                )\n",
    "                label_file = open(label_path, \"r\", newline=\"\")\n",
    "                label_reader = csv.reader(label_file, delimiter=\" \")\n",
    "                for _row in label_reader:\n",
    "                    _csv_rows.append(_row)\n",
    "                label_file.close()\n",
    "\n",
    "                label_path = os.path.join(\n",
    "                    os.path.join(_blur_save_label_pth),\n",
    "                    f\"blur_s{_blur_size}_a{_blur_angle}_{img_name.split('.')[0]}.txt\",\n",
    "                )\n",
    "                label_file = open(label_path, \"w\", newline=\"\")\n",
    "                label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "                for _r in _csv_rows:\n",
    "                    label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "                    label_writer.writerow(_r)\n",
    "                _csv_rows.clear()\n",
    "                label_file.close()\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=num_processes, verbose=1)(\n",
    "    delayed(adding_blur_to_image)(element) for element in _raw_saved_data_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into test, train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=20)]: Done 200 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=20)]: Done 700 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=20)]: Done 1400 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=20)]: Done 2300 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=20)]: Done 3400 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=20)]: Done 4700 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=20)]: Done 6200 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=20)]: Done 7900 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=20)]: Done 9800 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=20)]: Done 11900 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=20)]: Done 14200 tasks      | elapsed:   55.2s\n",
      "[Parallel(n_jobs=20)]: Done 16700 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=20)]: Done 19400 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=20)]: Done 22300 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=20)]: Done 22966 out of 23005 | elapsed:  1.6min remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 23005 out of 23005 | elapsed:  1.6min finished\n"
     ]
    }
   ],
   "source": [
    "# splitting dataset into train and validation and test\n",
    "split_data_name = \"processed\"\n",
    "\n",
    "images_pth = os.path.join(os.path.dirname(training_raw_data), split_data_name, \"images\")\n",
    "labels_pth = os.path.join(os.path.dirname(training_raw_data), split_data_name, \"labels\")\n",
    "\n",
    "if not os.path.exists(images_pth):\n",
    "    os.makedirs(os.path.join(images_pth, \"train\"))\n",
    "    os.makedirs(os.path.join(images_pth, \"val\"))\n",
    "    os.makedirs(os.path.join(images_pth, \"test\"))\n",
    "\n",
    "if not os.path.exists(labels_pth):\n",
    "    os.makedirs(os.path.join(labels_pth, \"train\"))\n",
    "    os.makedirs(os.path.join(labels_pth, \"val\"))\n",
    "    os.makedirs(os.path.join(labels_pth, \"test\"))\n",
    "\n",
    "\n",
    "image_list = os.listdir(os.path.join(training_raw_data, \"images\"))\n",
    "\n",
    "\n",
    "def split_dataset(img_name):\n",
    "    _image_path = os.path.join(training_raw_data, \"images\", img_name)\n",
    "    image = cv2.imread(_image_path)\n",
    "\n",
    "    label_name = img_name.split(\".\")[0]\n",
    "    label_path = os.path.join(training_raw_data, \"labels\", f\"{label_name}.txt\")\n",
    "    label_file = open(label_path, \"r\", newline=\"\")\n",
    "    label_reader = csv.reader(label_file, delimiter=\" \")\n",
    "\n",
    "    label = []\n",
    "    for l in label_reader:\n",
    "        label.append(l)\n",
    "\n",
    "    label_file.close()\n",
    "\n",
    "    # if int(label[0]) == 0:\n",
    "    if np.random.rand() < 0.7:\n",
    "        # save image\n",
    "        image_path = os.path.join(os.path.join(images_pth, \"train\"), img_name)\n",
    "        cv2.imwrite(image_path, image)\n",
    "\n",
    "        label_path = os.path.join(\n",
    "            os.path.join(labels_pth, \"train\"), f\"{label_name}.txt\"\n",
    "        )\n",
    "        label_file = open(label_path, \"w\", newline=\"\")\n",
    "        label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "        for l in label:\n",
    "            label_writer.writerow(l)\n",
    "        label_file.close()\n",
    "\n",
    "    elif np.random.rand() < 0.9 and np.random.rand() > 0.7:\n",
    "        # save image\n",
    "        image_path = os.path.join(os.path.join(images_pth, \"val\"), img_name)\n",
    "        cv2.imwrite(image_path, image)\n",
    "\n",
    "        label_path = os.path.join(os.path.join(labels_pth, \"val\"), f\"{label_name}.txt\")\n",
    "        label_file = open(label_path, \"w\", newline=\"\")\n",
    "        label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "        for l in label:\n",
    "            label_writer.writerow(l)\n",
    "        label_file.close()\n",
    "\n",
    "    else:\n",
    "        # save image\n",
    "        image_path = os.path.join(os.path.join(images_pth, \"test\"), img_name)\n",
    "        cv2.imwrite(image_path, image)\n",
    "\n",
    "        label_path = os.path.join(os.path.join(labels_pth, \"test\"), f\"{label_name}.txt\")\n",
    "        label_file = open(label_path, \"w\", newline=\"\")\n",
    "        label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "        for l in label:\n",
    "            label_writer.writerow(l)\n",
    "        label_file.close()\n",
    "\n",
    "    label.clear()\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=num_processes, verbose=1)(\n",
    "    delayed(split_dataset)(element) for element in image_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
