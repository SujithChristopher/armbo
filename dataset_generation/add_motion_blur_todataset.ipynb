{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import aruco\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import msgpack as mp\n",
    "import msgpack_numpy as mpn\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_parameters = [4, 6, 8, 10]\n",
    "angle_parameters = [0, 30, 60, 90, 120, 150, 180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processes = 20  # You can adjust this based on your requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_pth = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "raw_data_pth = os.path.join(raw_data_pth, 'dataset',\"multi_class\", \"raw_data\")\n",
    "\n",
    "_raw_saved_data_pth = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "_raw_saved_data_pth = os.path.join(_raw_saved_data_pth, 'dataset',\"multi_class\", \"raw_data\")\n",
    "_raw_saved_data_pth = os.path.join(_raw_saved_data_pth, \"images\")\n",
    "_raw_saved_data_list = os.listdir(_raw_saved_data_pth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "_blur_save_pth = os.path.dirname(os.path.dirname(_raw_saved_data_pth))\n",
    "_blur_save_pth = os.path.join(_blur_save_pth, 'motion_blur')\n",
    "_blur_save_img_pth = os.path.join(_blur_save_pth, \"images\")\n",
    "_blur_save_label_pth = os.path.join(_blur_save_pth, \"label\")\n",
    "\n",
    "if not os.path.exists(_blur_save_img_pth):\n",
    "    os.makedirs(_blur_save_img_pth)\n",
    "\n",
    "if not os.path.exists(_blur_save_label_pth):\n",
    "    os.makedirs(_blur_save_label_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_motion_blur(image, size, angle):\n",
    "    k = np.zeros((size, size), dtype=np.float32)\n",
    "    k[ (size-1)// 2 , :] = np.ones(size, dtype=np.float32)\n",
    "    k = cv2.warpAffine(k, cv2.getRotationMatrix2D( (size / 2 -0.5 , size / 2 -0.5 ) , angle, 1.0), (size, size) )  \n",
    "    k = k * ( 1.0 / np.sum(k) )        \n",
    "    return cv2.filter2D(image, -1, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done 219 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=20)]: Done 470 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=20)]: Done 820 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=20)]: Done 1270 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=20)]: Done 1820 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=20)]: Done 2470 tasks      | elapsed:   59.5s\n",
      "[Parallel(n_jobs=20)]: Done 3220 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=20)]: Done 4070 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=20)]: Done 5020 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=20)]: Done 6070 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=20)]: Done 7220 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=20)]: Done 7985 out of 7985 | elapsed:  3.8min finished\n"
     ]
    }
   ],
   "source": [
    "def adding_blur_to_image(img_name):\n",
    "    _image_path = os.path.join(_raw_saved_data_pth, img_name)\n",
    "    image = cv2.imread(_image_path)\n",
    "    #adding noise to twenty percent of the images\n",
    "    _csv_rows = []\n",
    "    \n",
    "    if np.random.random() < 0.4:\n",
    "        for _b in blur_parameters:\n",
    "            for _a in angle_parameters:\n",
    "                \n",
    "                _blur_size = _b\n",
    "                _blur_angle = _a\n",
    "                \n",
    "                image = apply_motion_blur(image, _blur_size, _blur_angle)        \n",
    "                \n",
    "                _image_path = os.path.join(_blur_save_img_pth, f\"blur_s{_blur_size}_a{_blur_angle}_{img_name}\")\n",
    "                cv2.imwrite(_image_path, image)\n",
    "                \n",
    "                label_name = img_name.split(\".\")[0]\n",
    "                label_path = os.path.join(_raw_saved_data_pth, \"..\",\"labels\", f\"{label_name}.txt\")\n",
    "                label_file = open(label_path, \"r\", newline='')\n",
    "                label_reader = csv.reader(label_file, delimiter=\" \")\n",
    "                for _row in label_reader:\n",
    "                    _csv_rows.append(_row)\n",
    "                label_file.close()\n",
    "\n",
    "                label_path = os.path.join(os.path.join(_blur_save_label_pth, \"..\", \"labels\"), f\"blur_s{_blur_size}_a{_blur_angle}_{img_name.split('.')[0]}.txt\")\n",
    "                label_file = open(label_path, \"w\", newline='')\n",
    "                label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "                for _r in _csv_rows:\n",
    "                    label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "                    label_writer.writerow(_r)\n",
    "                _csv_rows.clear()\n",
    "                label_file.close()\n",
    "\n",
    "    return 0\n",
    "        \n",
    "results = Parallel(n_jobs=num_processes, verbose=1)(delayed(adding_blur_to_image)(element) for element in _raw_saved_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=20)]: Done 260 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=20)]: Done 1260 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=20)]: Done 2660 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=20)]: Done 4460 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=20)]: Done 6660 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=20)]: Done 9260 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=20)]: Done 12260 tasks      | elapsed:   42.5s\n",
      "[Parallel(n_jobs=20)]: Done 15660 tasks      | elapsed:   54.1s\n",
      "[Parallel(n_jobs=20)]: Done 19460 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=20)]: Done 23660 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=20)]: Done 28260 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=20)]: Done 33260 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=20)]: Done 38660 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=20)]: Done 44460 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=20)]: Done 50660 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=20)]: Done 57260 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=20)]: Done 64260 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=20)]: Done 71660 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=20)]: Done 79460 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=20)]: Done 87660 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=20)]: Done 88609 out of 88648 | elapsed:  6.9min remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done 88648 out of 88648 | elapsed:  6.9min finished\n"
     ]
    }
   ],
   "source": [
    "# splitting dataset into train and validation and test\n",
    "data_pth = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "data_pth = os.path.join(data_pth, 'dataset',\"multi_class\", \"dataset_processed\")\n",
    "\n",
    "images_pth = os.path.join(data_pth, \"images\")\n",
    "labels_pth = os.path.join(data_pth, \"labels\")\n",
    "\n",
    "if not os.path.exists(images_pth):\n",
    "    os.makedirs(os.path.join(images_pth, \"train\"))\n",
    "    os.makedirs(os.path.join(images_pth, \"val\"))\n",
    "    os.makedirs(os.path.join(images_pth, \"test\"))\n",
    "\n",
    "if not os.path.exists(labels_pth):\n",
    "    os.makedirs(os.path.join(labels_pth, \"train\"))\n",
    "    os.makedirs(os.path.join(labels_pth, \"val\"))\n",
    "    os.makedirs(os.path.join(labels_pth, \"test\"))\n",
    "    \n",
    "    \n",
    "image_list = os.listdir(os.path.join(_blur_save_pth, \"images\"))\n",
    "\n",
    "def split_dataset(img_name):\n",
    "    _image_path = os.path.join(_blur_save_pth, \"images\", img_name)\n",
    "    image = cv2.imread(_image_path)\n",
    "    \n",
    "    label_name = img_name.split(\".\")[0]\n",
    "    label_path = os.path.join(_blur_save_pth, \"labels\", f\"{label_name}.txt\")\n",
    "    label_file = open(label_path, \"r\", newline='')\n",
    "    label_reader = csv.reader(label_file, delimiter=\" \")\n",
    "    \n",
    "    label = []\n",
    "    for l in label_reader:\n",
    "        label.append(l)\n",
    "    \n",
    "    label_file.close()\n",
    "    \n",
    "    # if int(label[0]) == 0:\n",
    "    if np.random.rand() < 0.7:\n",
    "        # save image\n",
    "        image_path = os.path.join(os.path.join(images_pth, \"train\"), img_name)\n",
    "        cv2.imwrite(image_path, image)\n",
    "        \n",
    "        label_path = os.path.join(os.path.join(labels_pth, \"train\"), f\"{label_name}.txt\")\n",
    "        label_file = open(label_path, \"w\", newline='')\n",
    "        label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "        for l in label:\n",
    "            label_writer.writerow(l)\n",
    "        label_file.close()\n",
    "        \n",
    "    elif np.random.rand() < 0.9 and np.random.rand() > 0.7:\n",
    "        # save image\n",
    "        image_path = os.path.join(os.path.join(images_pth, \"val\"), img_name)\n",
    "        cv2.imwrite(image_path, image)\n",
    "        \n",
    "        label_path = os.path.join(os.path.join(labels_pth, \"val\"), f\"{label_name}.txt\")\n",
    "        label_file = open(label_path, \"w\", newline='')\n",
    "        label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "        for l in label:\n",
    "            label_writer.writerow(l)\n",
    "        label_file.close()\n",
    "        \n",
    "    else:\n",
    "        # save image\n",
    "        image_path = os.path.join(os.path.join(images_pth, \"test\"), img_name)\n",
    "        cv2.imwrite(image_path, image)\n",
    "        \n",
    "        label_path = os.path.join(os.path.join(labels_pth, \"test\"), f\"{label_name}.txt\")\n",
    "        label_file = open(label_path, \"w\", newline='')\n",
    "        label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "        for l in label:\n",
    "            label_writer.writerow(l)\n",
    "        label_file.close() \n",
    "        \n",
    "    label.clear()\n",
    "        \n",
    "    return 0\n",
    "\n",
    "results = Parallel(n_jobs=num_processes, verbose=1)(delayed(split_dataset)(element) for element in image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
