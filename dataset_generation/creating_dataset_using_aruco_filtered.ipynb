{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import aruco\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, Image\n",
    "import msgpack as mp\n",
    "import msgpack_numpy as mpn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camera matrix [[880.19523452   0.         358.2789884 ]\n",
      " [  0.         881.87061144 242.70902376]\n",
      " [  0.           0.           1.        ]]\n",
      "distortion [[ 1.24325941e-01 -1.20330000e-01 -2.99461015e-03 -1.15851300e-03\n",
      "  -3.99283638e+00]]\n"
     ]
    }
   ],
   "source": [
    "_webcam_calib_folder = r\"C:\\Users\\CMC\\Documents\\openposelibs\\pose\\armbo\\recording_programs\\test_data\\omni_cam_9d0f_may_8_2023\\calibration_00\"\n",
    "# _webcam_calib_folder = r\"C:\\Users\\Sujith\\Documents\\Projects\\armbo\\recording_programs\\test_data\\omni_cam_9d0f_may_8_2023\\calibration_00\"\n",
    "\n",
    "_webcam_calib_folder = os.path.join(_webcam_calib_folder)\n",
    "_webcam_calib_pth = os.path.join( _webcam_calib_folder, \"webcam_calibration.msgpack\")\n",
    "\n",
    "with open(_webcam_calib_pth, \"rb\") as f:\n",
    "    webcam_calib = mp.Unpacker(f, object_hook=mpn.decode)\n",
    "    _temp = next(webcam_calib)\n",
    "    _webcam_cam_mat = _temp[0]\n",
    "    _webcam_dist = _temp[1]\n",
    "_webcam_video_pth = os.path.join(_webcam_calib_folder, \"webcam_color.msgpack\")\n",
    "_webcam_timestamp_pth = os.path.join(_webcam_calib_folder, \"webcam_timestamp.msgpack\")\n",
    "\n",
    "with open(os.path.join(_webcam_calib_folder, \"webcam_rotmat.msgpack\"), \"rb\") as f:\n",
    "    webcam_rotmat = mp.Unpacker(f, object_hook=mpn.decode)\n",
    "    _webcam_rot = next(webcam_rotmat)\n",
    "    _webcam_org = next(webcam_rotmat)\n",
    "print(\"camera matrix\", _webcam_cam_mat)\n",
    "print(\"distortion\", _webcam_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARUCO_PARAMETERS = aruco.DetectorParameters_create()\n",
    "ARUCO_DICT = aruco.Dictionary_get(aruco.DICT_ARUCO_ORIGINAL)\n",
    "markerLength = 0.05\n",
    "markerSeparation = 0.01\n",
    "\n",
    "board = aruco.GridBoard_create(\n",
    "        markersX=1,\n",
    "        markersY=1,\n",
    "        markerLength=markerLength,\n",
    "        markerSeparation=markerSeparation,\n",
    "        dictionary=ARUCO_DICT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect a ramdom image and show the rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(image):\n",
    "    img = image[...,::-1]/255.0\n",
    "    noise =  np.random.normal(loc=0, scale=1, size=img.shape)\n",
    "    img2 = img*2\n",
    "    n4 = np.clip(np.where(img2 <= 1, (img2*(1 + noise*0.4)), (1-img2+1)*(1 + noise*0.4)*-1 + 2)/2, 0,1)\n",
    "    return n4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [03:05<00:00, 23.17s/it]\n"
     ]
    }
   ],
   "source": [
    "_folder_names = os.listdir(os.path.dirname(_webcam_calib_folder))\n",
    "_folder_names.sort()\n",
    "_folder_names = _folder_names[3:]\n",
    "\n",
    "total_dummy_ids = []\n",
    "\n",
    "for _folder_name in tqdm(_folder_names):\n",
    "    _video_pth = os.path.join(os.path.dirname(_webcam_calib_folder), _folder_name, \"webcam_color.msgpack\")\n",
    "    _video_file = open(_video_pth, \"rb\")\n",
    "    _video = mp.Unpacker(_video_file, object_hook=mpn.decode)\n",
    "\n",
    "    coord = {\"x\":[], \"y\":[], \"z\":[]}\n",
    "\n",
    "    dummy_ids = []\n",
    "\n",
    "    for frame_id, frame in enumerate(_video):\n",
    "        # gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = frame\n",
    "        # estimate pose of aruco markers\n",
    "        corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, ARUCO_DICT, parameters=ARUCO_PARAMETERS)\n",
    "        # Refine detected markers\n",
    "        # Eliminates markers not part of our board, adds missing markers to the board\n",
    "        corners, ids, rejectedImgPoints, recoveredIds = aruco.refineDetectedMarkers(\n",
    "                image = gray,\n",
    "                board = board,\n",
    "                detectedCorners = corners,\n",
    "                detectedIds = ids,\n",
    "                rejectedCorners = rejectedImgPoints,\n",
    "                cameraMatrix = _webcam_cam_mat,\n",
    "                distCoeffs = _webcam_dist)\n",
    "\n",
    "        rotation_vectors, translation_vectors, _ = aruco.estimatePoseSingleMarkers(corners, 0.05, _webcam_cam_mat, _webcam_dist)\n",
    "\n",
    "        if translation_vectors is None:\n",
    "            coord[\"x\"].append(np.nan)\n",
    "            coord[\"y\"].append(np.nan)\n",
    "            coord[\"z\"].append(np.nan)\n",
    "            dummy_ids.append(frame_id)\n",
    "            \n",
    "        else:\n",
    "            coord[\"x\"].append(translation_vectors[0][0][0])\n",
    "            coord[\"y\"].append(translation_vectors[0][0][1])\n",
    "            coord[\"z\"].append(translation_vectors[0][0][2])\n",
    "\n",
    "    for idx, val in enumerate(coord[\"z\"]):\n",
    "        if idx == 0:\n",
    "            continue\n",
    "        else:\n",
    "            if abs(coord[\"z\"][idx] - coord[\"z\"][idx-1]) > 0.06:\n",
    "                dummy_ids.append(idx)\n",
    "            try:\n",
    "                if abs(coord[\"z\"][idx] - coord[\"z\"][idx+1]) > 0.06:\n",
    "                    dummy_ids.append(idx)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    for idx, val in enumerate(coord[\"x\"]):\n",
    "        if idx == 0:\n",
    "            continue\n",
    "        else:\n",
    "            if abs(coord[\"x\"][idx] - coord[\"x\"][idx-1]) > 0.1:\n",
    "                dummy_ids.append(idx)\n",
    "            try:\n",
    "                if abs(coord[\"x\"][idx] - coord[\"x\"][idx+1]) > 0.1:\n",
    "                    dummy_ids.append(idx)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    total_dummy_ids.append(dummy_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_pth = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "raw_data_pth = os.path.join(raw_data_pth, 'dataset', \"raw_data\")\n",
    "if not os.path.exists(raw_data_pth):\n",
    "    os.makedirs(os.path.join(raw_data_pth, \"images\"))\n",
    "    os.makedirs(os.path.join(raw_data_pth, \"labels\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 sk36_30_forward_slow_00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:43, 43.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 sk36_30_forward_slow_01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:39, 50.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 sk36_30_forward_slow_02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [02:25, 48.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 sk36_30_forward_slow_03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [03:16, 49.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 sk36_30_random_00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [04:21, 55.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 sk36_30_random_01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [05:23, 57.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 sk36_30_sideways_00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [06:46, 65.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 sk36_30_sideways_01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [07:31, 56.46s/it]\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for _folder_id, _folder_name in tqdm(enumerate(_folder_names)):\n",
    "    print(_folder_id, _folder_name)\n",
    "    _video_pth = os.path.join(os.path.dirname(_webcam_calib_folder), _folder_name, \"webcam_color.msgpack\")\n",
    "    _video_file = open(_video_pth, \"rb\")\n",
    "    _video = mp.Unpacker(_video_file, object_hook=mpn.decode)\n",
    "    height, width = next(_video).shape\n",
    "    _video_file.close()\n",
    "    _video_file = open(_video_pth, \"rb\")\n",
    "    _video = mp.Unpacker(_video_file, object_hook=mpn.decode)\n",
    "\n",
    "    fake_id = total_dummy_ids[_folder_id]\n",
    "\n",
    "    for image_id, image in enumerate(_video):\n",
    "\n",
    "        if image_id in fake_id:\n",
    "            continue\n",
    "\n",
    "        markerCorners, markerIds, rejected_img_points = aruco.detectMarkers(image, ARUCO_DICT, parameters=ARUCO_PARAMETERS)\n",
    "        markerCorners, markerIds, rejectedImgPoints, recoveredIds = aruco.refineDetectedMarkers(\n",
    "                image = image,\n",
    "                board = board,\n",
    "                detectedCorners = markerCorners,\n",
    "                detectedIds = markerIds,\n",
    "                rejectedCorners = rejected_img_points,\n",
    "                cameraMatrix = _webcam_cam_mat,\n",
    "                distCoeffs = _webcam_dist)\n",
    "        \n",
    "        if len(markerCorners) == 0:\n",
    "            continue\n",
    "            \n",
    "        img_name = f\"image{counter}.png\"\n",
    "        \n",
    "        label_name = img_name.split(\".\")[0]\n",
    "        label_path = os.path.join(raw_data_pth, \"labels\", f\"{label_name}.txt\")\n",
    "        label_file = open(label_path, \"w\")\n",
    "        label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "        _markerCorners = markerCorners[0][0]\n",
    "\n",
    "        bbox_x,bbox_y,bbox_width,bbox_height = cv2.boundingRect(_markerCorners)\n",
    "\n",
    "        # normalize the values\n",
    "        bbox_x = bbox_x / width\n",
    "        bbox_y = bbox_y / height\n",
    "\n",
    "        bbox_center_x = bbox_x + bbox_width / (2 * width)\n",
    "        bbox_center_y = bbox_y + bbox_height / (2 * height)\n",
    "\n",
    "        bbox_width = bbox_width / width\n",
    "        bbox_height = bbox_height / height\n",
    "\n",
    "        label_writer.writerow([\"0\", bbox_center_x, bbox_center_y, bbox_width, bbox_height,_markerCorners[0][0]/width, _markerCorners[0][1]/height, _markerCorners[1][0]/width, _markerCorners[1][1]/height, _markerCorners[2][0]/width, _markerCorners[2][1]/height, _markerCorners[3][0]/width, _markerCorners[3][1]/height, _markerCorners[0][0]/width, _markerCorners[0][1]/height])\n",
    "\n",
    "        label_file.close()\n",
    "        \n",
    "        # save image\n",
    "        image_path = os.path.join(raw_data_pth, \"images\", img_name)\n",
    "        cv2.imwrite(image_path, image)\n",
    "\n",
    "        counter += 1 # increment counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11987/11987 [21:11<00:00,  9.43it/s] \n"
     ]
    }
   ],
   "source": [
    "_raw_saved_data_pth = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "_raw_saved_data_pth = os.path.join(_raw_saved_data_pth, 'dataset', \"raw_data\")\n",
    "_raw_saved_data_pth = os.path.join(_raw_saved_data_pth, \"images\")\n",
    "_raw_saved_data_list = os.listdir(_raw_saved_data_pth)\n",
    "\n",
    "def gaussian_noise(image):\n",
    "\n",
    "    gauss_noise=np.zeros(image.shape, dtype=np.uint8)\n",
    "    cv2.randn(gauss_noise, 0, 5)\n",
    "    gauss_noise=(gauss_noise*0.5).astype(np.uint8)\n",
    "    gn_img = cv2.add(image,gauss_noise)\n",
    "    return gn_img\n",
    "\n",
    "def gaussian_blur(image):\n",
    "    return cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "#adding noise to twenty percent of the images\n",
    "for img_name in tqdm(_raw_saved_data_list):\n",
    "    _image_path = os.path.join(_raw_saved_data_pth, img_name)\n",
    "    image = cv2.imread(_image_path)\n",
    "    #adding noise to twenty percent of the images\n",
    "    if np.random.random() < 0.2:\n",
    "        image = gaussian_blur(image)\n",
    "        _image_path = os.path.join(_raw_saved_data_pth, f\"blur_{img_name}\")\n",
    "        cv2.imwrite(_image_path, image)\n",
    "\n",
    "        label_name = img_name.split(\".\")[0]\n",
    "        label_path = os.path.join(_raw_saved_data_pth, \"..\",\"labels\", f\"{label_name}.txt\")\n",
    "        label_file = open(label_path, \"r\")\n",
    "        label_reader = csv.reader(label_file, delimiter=\" \")\n",
    "        label = list(label_reader)[0]\n",
    "        label_file.close()\n",
    "\n",
    "        label_path = os.path.join(os.path.join(_raw_saved_data_pth, \"..\", \"labels\"), f\"blur_{img_name.split('.')[0]}.txt\")\n",
    "        label_file = open(label_path, \"w\")\n",
    "        label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "        label_writer.writerow(label)\n",
    "        label_file.close()\n",
    "    \n",
    "    if np.random.random() > 0.2 and np.random.random()<0.4:\n",
    "        image = add_noise(image)\n",
    "        image = (image*255).astype(np.uint8)\n",
    "        _image_path = os.path.join(_raw_saved_data_pth, f\"noise_{img_name}\")\n",
    "        \n",
    "        cv2.imwrite(_image_path, image)\n",
    "\n",
    "        label_name = img_name.split(\".\")[0]\n",
    "        label_path = os.path.join(_raw_saved_data_pth, \"..\",\"labels\", f\"{label_name}.txt\")\n",
    "        label_file = open(label_path, \"r\")\n",
    "        label_reader = csv.reader(label_file, delimiter=\" \")\n",
    "        label = list(label_reader)[0]\n",
    "        label_file.close()\n",
    "\n",
    "        label_path = os.path.join(os.path.join(_raw_saved_data_pth, \"..\", \"labels\"), f\"noise_{img_name.split('.')[0]}.txt\")\n",
    "        label_file = open(label_path, \"w\")\n",
    "        label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "        label_writer.writerow(label)\n",
    "        label_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding noise to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2973 1963\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(os.path.join(raw_data_pth, \"labels\"))), len(image_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting it into traning and testing dataset based on COCOv8 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18230/18230 [28:53<00:00, 10.52it/s]  \n"
     ]
    }
   ],
   "source": [
    "# splitting dataset into train and validation and test\n",
    "data_pth = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "data_pth = os.path.join(data_pth, 'dataset', \"dataset_processed\")\n",
    "\n",
    "images_pth = os.path.join(data_pth, \"images\")\n",
    "labels_pth = os.path.join(data_pth, \"labels\")\n",
    "\n",
    "if not os.path.exists(images_pth):\n",
    "    os.makedirs(os.path.join(images_pth, \"train\"))\n",
    "    os.makedirs(os.path.join(images_pth, \"val\"))\n",
    "    os.makedirs(os.path.join(images_pth, \"test\"))\n",
    "\n",
    "if not os.path.exists(labels_pth):\n",
    "    os.makedirs(os.path.join(labels_pth, \"train\"))\n",
    "    os.makedirs(os.path.join(labels_pth, \"val\"))\n",
    "    os.makedirs(os.path.join(labels_pth, \"test\"))\n",
    "    \n",
    "    \n",
    "image_list = os.listdir(os.path.join(raw_data_pth, \"images\"))\n",
    "\n",
    "# splitting dataset into train and test\n",
    "for img_name in tqdm(image_list):\n",
    "    \n",
    "    _image_path = os.path.join(raw_data_pth, \"images\", img_name)\n",
    "    image = cv2.imread(_image_path)\n",
    "    \n",
    "    label_name = img_name.split(\".\")[0]\n",
    "    label_path = os.path.join(raw_data_pth, \"labels\", f\"{label_name}.txt\")\n",
    "    label_file = open(label_path, \"r\")\n",
    "    label_reader = csv.reader(label_file, delimiter=\" \")\n",
    "    label = list(label_reader)[0]\n",
    "    label_file.close()\n",
    "    \n",
    "    if int(label[0]) == 0:\n",
    "        if np.random.rand() < 0.7:\n",
    "            # save image\n",
    "            image_path = os.path.join(os.path.join(images_pth, \"train\"), img_name)\n",
    "            cv2.imwrite(image_path, image)\n",
    "            \n",
    "            label_path = os.path.join(os.path.join(labels_pth, \"train\"), f\"{label_name}.txt\")\n",
    "            label_file = open(label_path, \"w\")\n",
    "            label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "            label_writer.writerow(label)\n",
    "            label_file.close()\n",
    "            \n",
    "        elif np.random.rand() < 0.9 and np.random.rand() > 0.7:\n",
    "            # save image\n",
    "            image_path = os.path.join(os.path.join(images_pth, \"val\"), img_name)\n",
    "            cv2.imwrite(image_path, image)\n",
    "            \n",
    "            label_path = os.path.join(os.path.join(labels_pth, \"val\"), f\"{label_name}.txt\")\n",
    "            label_file = open(label_path, \"w\")\n",
    "            label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "            label_writer.writerow(label)\n",
    "            label_file.close()\n",
    "            \n",
    "        else:\n",
    "            # save image\n",
    "            image_path = os.path.join(os.path.join(images_pth, \"test\"), img_name)\n",
    "            cv2.imwrite(image_path, image)\n",
    "            \n",
    "            label_path = os.path.join(os.path.join(labels_pth, \"test\"), f\"{label_name}.txt\")\n",
    "            label_file = open(label_path, \"w\")\n",
    "            label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "            label_writer.writerow(label)\n",
    "            label_file.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
