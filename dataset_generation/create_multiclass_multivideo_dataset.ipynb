{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import msgpack as mp\n",
    "import msgpack_numpy as mpn\n",
    "import toml\n",
    "import cv2\n",
    "from cv2 import aruco\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FORMAT: SEGMENTATION, CLASSIFICATION, POSE\n",
    "#TODO: remove combining of all data\n",
    "DATASET_FORMAT = \"POSE\"\n",
    "RECORDING_TYPE = \"MULTIVIDEO\"\n",
    "FILTER_BASED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the parameter.toml for different directory\n",
    "Defining folders and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_analysis\n",
      "F:\\\\aruco_recent_recordings\\\\data_for_labelling_aug_1_2023\n",
      "F:\\\\aruco_recent_recordings\\\\data_for_labelling_aug_1_2023\\00_analysis\\folder_names.txt\n"
     ]
    }
   ],
   "source": [
    "data_pth = toml.load(os.path.join(os.path.dirname(os.getcwd()), 'parameters.toml'))['raw_dataset']['pth']\n",
    "process_file = os.listdir(data_pth)[os.listdir(data_pth).index('00_analysis')]\n",
    "analysis_folder = os.path.join(data_pth, process_file)\n",
    "analysis_file = os.path.join(analysis_folder, 'folder_names.txt')\n",
    "\n",
    "training_pth = toml.load(os.path.join(os.path.dirname(os.getcwd()), 'parameters.toml'))['training_dataset']['pth']\n",
    "training_raw_data = os.path.join(training_pth, 'raw_data')\n",
    "\n",
    "if not os.path.exists(training_raw_data):\n",
    "    os.mkdir(training_raw_data)\n",
    "    os.mkdir(os.path.join(training_raw_data, 'labels'))\n",
    "    os.mkdir(os.path.join(training_raw_data, 'images'))\n",
    "\n",
    "print(process_file)\n",
    "print(data_pth)\n",
    "print(analysis_file)\n",
    "\n",
    "video_folders_list = os.listdir(os.path.join(data_pth))\n",
    "\n",
    "\"\"\"write folder names to text file\"\"\"\n",
    "with open(analysis_file, \"w\") as f:\n",
    "    for i in video_folders_list:\n",
    "        f.write(i + \"\\n\")\n",
    "        pass\n",
    "\n",
    "with open(analysis_file, \"r\") as f:\n",
    "    video_folders_list = f.readlines()\n",
    "    video_folders_list = [i.strip() for i in video_folders_list]\n",
    "    \n",
    "video_folders_list = video_folders_list[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mip_brd_30_4_0',\n",
       " 'mip_brd_30_4_1_angle',\n",
       " 'mip_brd_30_5_0',\n",
       " 'mip_brd_30_5_1_angle',\n",
       " 'mip_obj_30_4_0',\n",
       " 'mip_obj_30_4_1',\n",
       " 'mip_obj_30_5_0',\n",
       " 'mip_obj_30_5_1',\n",
       " 'mip_obj_30_5_2',\n",
       " 'mip_quad_30_5_0',\n",
       " 'mip_quad_30_5_1',\n",
       " 'mip_quad_30_5_2',\n",
       " 'mip_sk_30_4_0',\n",
       " 'mip_sk_30_4_1',\n",
       " 'mip_sk_30_5_0',\n",
       " 'mip_sk_30_5_1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_folders_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration files path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[671.25534529,   0.        , 678.00736213],\n",
       "       [  0.        , 692.23316717, 443.37269229],\n",
       "       [  0.        ,   0.        ,   1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_calib_folder_name = \"calibration_00\"\n",
    "_webcam_calib_pth = os.path.join(data_pth, os.path.dirname(process_file), _calib_folder_name, \"webcam_calibration.msgpack\")\n",
    "\n",
    "with open(_webcam_calib_pth, \"rb\") as f:\n",
    "    webcam_calib = mp.Unpacker(f, object_hook=mpn.decode)\n",
    "    _temp = next(webcam_calib)\n",
    "    _webcam_cam_mat = _temp[0]\n",
    "    _webcam_dist = _temp[1]\n",
    "\n",
    "_webcam_cam_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArUco dictionary and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_size = 0.05\n",
    "\n",
    "marker_points = np.array([[-marker_size / 2, marker_size / 2, 0],\n",
    "                            [marker_size / 2, marker_size / 2, 0],\n",
    "                            [marker_size / 2, -marker_size / 2, 0],\n",
    "                            [-marker_size / 2, -marker_size / 2, 0]], dtype=np.float32)\n",
    "\n",
    "ARUCO_PARAMETERS = aruco.DetectorParameters()\n",
    "ARUCO_DICT = aruco.getPredefinedDictionary(aruco.DICT_ARUCO_MIP_36H12)\n",
    "detector = aruco.ArucoDetector(ARUCO_DICT, ARUCO_PARAMETERS)\n",
    "markerLength = marker_size\n",
    "markerSeperation = 0.01\n",
    "\n",
    "board = aruco.GridBoard(\n",
    "        size= [1,1],\n",
    "        markerLength=markerLength,\n",
    "        markerSeparation=markerSeperation,\n",
    "        dictionary=ARUCO_DICT)\n",
    "\n",
    "def my_estimatePoseSingleMarkers(corners, marker_points, mtx, distortion):\n",
    "    trash = []\n",
    "    rvecs = []\n",
    "    tvecs = []\n",
    "    for c in corners:\n",
    "        nada, R, t = cv2.solvePnP(marker_points, c, mtx, distortion, False, flags= cv2.SOLVEPNP_ITERATIVE)\n",
    "        R = R.T\n",
    "        t = t.T\n",
    "        rvecs.append(R)\n",
    "        tvecs.append(t)\n",
    "        trash.append(nada)\n",
    "    return rvecs, tvecs, trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:19<00:00,  4.98s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "default_ids = [12, 88, 89]\n",
    "data = {\"frame_id\":[],\"marker_ids\":[], \"corners\":[], \"tvec\":[], \"rvec\":[]}\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for _name in tqdm(video_folders_list):\n",
    "    _video_path = os.path.join(data_pth, os.path.dirname(process_file), _name, 'webcam_color.msgpack')\n",
    "    _video_file = mp.Unpacker(open(_video_path, \"rb\"), object_hook=mpn.decode)\n",
    "    detector = aruco.ArucoDetector(ARUCO_DICT, ARUCO_PARAMETERS)\n",
    "\n",
    "\n",
    "    for _frame in _video_file:\n",
    "        shape = _frame.shape\n",
    "        gray = cv2.cvtColor(_frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        corners, ids, rejectedImgPoints = detector.detectMarkers(gray)\n",
    "        corners, ids, rejectedImgPoints,_ = detector.refineDetectedMarkers(image=gray,board=board ,detectedCorners=corners, detectedIds=ids, \n",
    "                                                                        rejectedCorners=rejectedImgPoints, cameraMatrix=_webcam_cam_mat, \n",
    "                                                                        distCoeffs=_webcam_dist)\n",
    "\n",
    "        rotation_vectors, translation_vectors, _ = my_estimatePoseSingleMarkers(corners, marker_points, _webcam_cam_mat, _webcam_dist)\n",
    "\n",
    "        if ids is None:\n",
    "            data[\"frame_id\"].append(counter)\n",
    "            data[\"marker_ids\"].append(None)\n",
    "            data[\"corners\"].append(None)\n",
    "            data[\"tvec\"].append(None)\n",
    "            data[\"rvec\"].append(None)\n",
    "\n",
    "        if ids is not None:\n",
    "            data[\"frame_id\"].append(counter)\n",
    "            data[\"marker_ids\"].append(ids)\n",
    "            data[\"corners\"].append(corners)\n",
    "            data[\"tvec\"].append(translation_vectors)\n",
    "            data[\"rvec\"].append(rotation_vectors)\n",
    "\n",
    "        counter+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate = {str(default_ids[0]):{\"x\":[], \"y\":[], \"z\":[], \"rx\":[], \"ry\":[], \"rz\":[]},\n",
    "              str(default_ids[1]):{\"x\":[], \"y\":[], \"z\":[], \"rx\":[], \"ry\":[], \"rz\":[]},\n",
    "              str(default_ids[2]):{\"x\":[], \"y\":[], \"z\":[], \"rx\":[], \"ry\":[], \"rz\":[]}}\n",
    "\n",
    "doesnt_exist = [] # list of ids that doesnt exist in a frame\n",
    "\n",
    "for i in range(len(data[\"frame_id\"])):\n",
    "    if data[\"marker_ids\"][i] is not None:\n",
    "\n",
    "        if default_ids[0] not in data[\"marker_ids\"][i]:\n",
    "            doesnt_exist.append(default_ids[0])\n",
    "        if default_ids[1] not in data[\"marker_ids\"][i]:\n",
    "            doesnt_exist.append(default_ids[1])\n",
    "        if default_ids[2] not in data[\"marker_ids\"][i]:\n",
    "            doesnt_exist.append(default_ids[2])\n",
    "\n",
    "        for j in range(len(data[\"marker_ids\"][i])):\n",
    "            if data[\"marker_ids\"][i][j] in default_ids:\n",
    "                coordinate[str(data[\"marker_ids\"][i][j][0])][\"x\"].append(data[\"tvec\"][i][j][0][0])\n",
    "                coordinate[str(data[\"marker_ids\"][i][j][0])][\"y\"].append(data[\"tvec\"][i][j][0][1])\n",
    "                coordinate[str(data[\"marker_ids\"][i][j][0])][\"z\"].append(data[\"tvec\"][i][j][0][2])\n",
    "                coordinate[str(data[\"marker_ids\"][i][j][0])][\"rx\"].append(data[\"rvec\"][i][j][0][0])\n",
    "                coordinate[str(data[\"marker_ids\"][i][j][0])][\"ry\"].append(data[\"rvec\"][i][j][0][1])\n",
    "                coordinate[str(data[\"marker_ids\"][i][j][0])][\"rz\"].append(data[\"rvec\"][i][j][0][2])\n",
    "        for k in doesnt_exist:\n",
    "            coordinate[str(k)][\"x\"].append(np.nan)\n",
    "            coordinate[str(k)][\"y\"].append(np.nan)\n",
    "            coordinate[str(k)][\"z\"].append(np.nan)\n",
    "            coordinate[str(k)][\"rx\"].append(np.nan)\n",
    "            coordinate[str(k)][\"ry\"].append(np.nan)\n",
    "            coordinate[str(k)][\"rz\"].append(np.nan)\n",
    "        doesnt_exist = []\n",
    "    else:\n",
    "        for k in default_ids:\n",
    "            coordinate[str(k)][\"x\"].append(np.nan)\n",
    "            coordinate[str(k)][\"y\"].append(np.nan)\n",
    "            coordinate[str(k)][\"z\"].append(np.nan)\n",
    "            coordinate[str(k)][\"rx\"].append(np.nan)\n",
    "            coordinate[str(k)][\"ry\"].append(np.nan)\n",
    "            coordinate[str(k)][\"rz\"].append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_df_12 = pd.DataFrame(coordinate['12'])\n",
    "ar_df_12['sort'] = (ar_df_12['z'].diff()>1)\n",
    "drop_idx_12 = ar_df_12.query('sort == True').index\n",
    "\n",
    "ar_df_88 = pd.DataFrame(coordinate['88'])\n",
    "ar_df_88['sort'] = (ar_df_88['z'].diff()>1)\n",
    "drop_idx_88 = ar_df_88.query('sort == True').index\n",
    "\n",
    "ar_df_89 = pd.DataFrame(coordinate['89'])\n",
    "ar_df_89['sort'] = (ar_df_89['z'].diff()>1)\n",
    "drop_idx_89 = ar_df_89.query('sort == True').index\n",
    "\n",
    "drop_ids = []\n",
    "for i in drop_idx_12:\n",
    "    drop_ids.append(i)\n",
    "for i in drop_idx_88:\n",
    "    drop_ids.append(i)\n",
    "for i in drop_idx_89:\n",
    "    drop_ids.append(i)\n",
    "drop = {'drop':drop_ids}\n",
    "drop_ids = pl.DataFrame(drop)\n",
    "drops = drop_ids['drop'].unique().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [05:04<00:00, 19.02s/it]\n"
     ]
    }
   ],
   "source": [
    "default_ids = [12, 88, 89]\n",
    "data = {\"frame_id\":[],\"marker_ids\":[], \"corners\":[], \"tvec\":[], \"rvec\":[]}\n",
    "\n",
    "counter = 0\n",
    "second_counter = 0\n",
    "\n",
    "for _name in tqdm(video_folders_list):\n",
    "\n",
    "    _video_path = os.path.join(data_pth, os.path.dirname(process_file), _name, 'webcam_color.msgpack')\n",
    "    _video_file = mp.Unpacker(open(_video_path, \"rb\"), object_hook=mpn.decode)\n",
    "\n",
    "    detector = aruco.ArucoDetector(ARUCO_DICT, ARUCO_PARAMETERS)\n",
    "\n",
    "    for _frame in _video_file:\n",
    "        \n",
    "        height, width = _frame.shape[:2]\n",
    "        gray = cv2.cvtColor(_frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        markerCorners, ids, rejectedImgPoints = detector.detectMarkers(gray)\n",
    "        \n",
    "        markerCorners, ids, rejectedImgPoints,_ = detector.refineDetectedMarkers(image=gray,board=board ,detectedCorners=markerCorners, detectedIds=ids, \n",
    "                                                                    rejectedCorners=rejectedImgPoints, cameraMatrix=_webcam_cam_mat, \n",
    "                                                                    distCoeffs=_webcam_dist)\n",
    "\n",
    "        counter += 1\n",
    "        \n",
    "        if counter in drops:\n",
    "            continue\n",
    "        \n",
    "        second_counter += 1\n",
    "        \n",
    "        img_name = f\"image_{counter}.png\"\n",
    "\n",
    "        label_name = img_name.split(\".\")[0]\n",
    "        label_path = os.path.join(training_raw_data, \"labels\", f\"{label_name}.txt\")\n",
    "        label_file = open(label_path, \"w\", newline='')\n",
    "        label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "\n",
    "        _class_name = \"\"\n",
    "        \n",
    "        for i in range(len(ids)):\n",
    "            \n",
    "            _markerCorners = markerCorners[i][0]\n",
    "            bbox_x,bbox_y,bbox_width,bbox_height = cv2.boundingRect(_markerCorners)\n",
    "\n",
    "            bbox_x = bbox_x / width\n",
    "            bbox_y = bbox_y / height\n",
    "\n",
    "            bbox_center_x = bbox_x + bbox_width / (2 * width)\n",
    "            bbox_center_y = bbox_y + bbox_height / (2 * height)\n",
    "\n",
    "            bbox_width = bbox_width / width\n",
    "            bbox_height = bbox_height / height\n",
    "            if ids[i][0] == default_ids[0]:\n",
    "                _class_name = \"0\"\n",
    "            elif ids[i][0] == default_ids[1]:\n",
    "                _class_name = \"1\"\n",
    "            elif ids[i][0] == default_ids[2]:\n",
    "                _class_name = \"2\"\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "            if DATASET_FORMAT == \"SEGMENTATION\":\n",
    "                label_writer.writerow([_class_name,_markerCorners[0][0]/width, _markerCorners[0][1]/height, _markerCorners[1][0]/width, _markerCorners[1][1]/height, _markerCorners[2][0]/width, _markerCorners[2][1]/height, _markerCorners[3][0]/width, _markerCorners[3][1]/height, _markerCorners[0][0]/width, _markerCorners[0][1]/height])\n",
    "            elif DATASET_FORMAT == \"POSE\":\n",
    "                label_writer.writerow([_class_name, bbox_center_x, bbox_center_y, bbox_width, bbox_height,_markerCorners[0][0]/width, _markerCorners[0][1]/height, _markerCorners[1][0]/width, _markerCorners[1][1]/height, _markerCorners[2][0]/width, _markerCorners[2][1]/height, _markerCorners[3][0]/width, _markerCorners[3][1]/height, _markerCorners[0][0]/width, _markerCorners[0][1]/height])\n",
    "        \n",
    "        \n",
    "        label_file.close()\n",
    "        image_path = os.path.join(training_raw_data, \"images\", img_name)\n",
    "        cv2.imwrite(image_path, _frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12573, 12572)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter, second_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding gaussian blur and salt and pepper noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processes = 20  # You can adjust this based on your requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=20)]: Done 580 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=20)]: Done 1280 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=20)]: Done 2180 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=20)]: Done 3280 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=20)]: Done 4580 tasks      | elapsed:   49.9s\n",
      "[Parallel(n_jobs=20)]: Done 6080 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=20)]: Done 7780 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=20)]: Done 9680 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=20)]: Done 11780 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=20)]: Done 12533 out of 12572 | elapsed:  2.3min remaining:    0.3s\n",
      "[Parallel(n_jobs=20)]: Done 12572 out of 12572 | elapsed:  2.3min finished\n"
     ]
    }
   ],
   "source": [
    "_raw_saved_data_pth = os.path.join(training_raw_data, \"images\")\n",
    "_raw_saved_data_list = os.listdir(os.path.join(training_raw_data, \"images\"))\n",
    "\n",
    "def add_noise(image):\n",
    "    img = image[...,::-1]/255.0\n",
    "    noise =  np.random.normal(loc=0, scale=1, size=img.shape)\n",
    "    noisy2 = np.clip((img + noise*0.4),0,1)\n",
    "    noisy2 = (noisy2*255).astype(np.uint8)\n",
    "    noisy2 = noisy2[...,::-1]\n",
    "    return noisy2\n",
    "\n",
    "def gaussian_blur(image):\n",
    "    return cv2.GaussianBlur(image, (3, 35), 0)\n",
    "\n",
    "\n",
    "def adding_noise_to_image(img_name):\n",
    "    _image_path = os.path.join(_raw_saved_data_pth, img_name)\n",
    "    image = cv2.imread(_image_path)\n",
    "    #adding noise to twenty percent of the images\n",
    "    _csv_rows = []\n",
    "    if np.random.random() < 0.4:\n",
    "        image = gaussian_blur(image)\n",
    "        _image_path = os.path.join(_raw_saved_data_pth, f\"blur_{img_name}\")\n",
    "        cv2.imwrite(_image_path, image)\n",
    "\n",
    "        label_name = img_name.split(\".\")[0]\n",
    "        label_path = os.path.join(_raw_saved_data_pth, \"..\",\"labels\", f\"{label_name}.txt\")\n",
    "        label_file = open(label_path, \"r\", newline='')\n",
    "        label_reader = csv.reader(label_file, delimiter=\" \")\n",
    "        for _row in label_reader:\n",
    "            _csv_rows.append(_row)\n",
    "        label_file.close()\n",
    "\n",
    "        label_path = os.path.join(os.path.join(_raw_saved_data_pth, \"..\", \"labels\"), f\"blur_{img_name.split('.')[0]}.txt\")\n",
    "        label_file = open(label_path, \"w\", newline='')\n",
    "        label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "        for _r in _csv_rows:\n",
    "            label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "            label_writer.writerow(_r)\n",
    "            \n",
    "        _csv_rows.clear()\n",
    "        label_file.close()\n",
    "    \n",
    "    if np.random.random() > 0.3 and np.random.random()<0.6:\n",
    "        image = add_noise(image)        \n",
    "        _image_path = os.path.join(_raw_saved_data_pth, f\"noise_{img_name}\")\n",
    "        cv2.imwrite(_image_path, image)\n",
    "\n",
    "        label_name = img_name.split(\".\")[0]\n",
    "        label_path = os.path.join(_raw_saved_data_pth, \"..\",\"labels\", f\"{label_name}.txt\")\n",
    "        label_file = open(label_path, \"r\", newline='')\n",
    "        label_reader = csv.reader(label_file, delimiter=\" \")\n",
    "        for _row in label_reader:\n",
    "            _csv_rows.append(_row)\n",
    "        label_file.close()\n",
    "\n",
    "        label_path = os.path.join(os.path.join(_raw_saved_data_pth, \"..\", \"labels\"), f\"noise_{img_name.split('.')[0]}.txt\")\n",
    "        label_file = open(label_path, \"w\", newline='')\n",
    "        label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "        for _r in _csv_rows:\n",
    "            label_writer = csv.writer(label_file, delimiter=\" \")\n",
    "            label_writer.writerow(_r)\n",
    "            \n",
    "        _csv_rows.clear()\n",
    "        label_file.close()\n",
    "    return 0\n",
    "        \n",
    "results = Parallel(n_jobs=num_processes, verbose=1)(delayed(adding_noise_to_image)(element) for element in _raw_saved_data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py115",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
