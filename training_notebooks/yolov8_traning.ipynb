{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "from ultralytics.utils.benchmarks import benchmark\n",
    "import yaml\n",
    "import ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.147  Python-3.11.4 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Setup complete  (24 CPUs, 15.7 GB RAM, 202.6/280.0 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# check if YOLO\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = YOLO('yolov8n-pose.pt')\n",
    "model = YOLO(r'D:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\\last.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDict = {\"path\":\"../dataset/multi_class/dataset_processed/dataset.yaml\",\n",
    "          \"train\":\"../dataset/multi_class/dataset_processed/images/train\",\n",
    "          \"val\":\"../dataset/multi_class/dataset_processed/images/val\",\n",
    "          \"test\":\"../dataset/multi_class/dataset_processed/images/test\",\n",
    "          \"kpt_shape\":[5, 2],\n",
    "          'names': {0: '0',\n",
    "                    1: \"49\",\n",
    "                    2: \"80\"}\n",
    "          }\n",
    "\n",
    "# with open(\"../dataset/multi_class/dataset_processed/dataset.yaml\", 'w') as file:\n",
    "#     documents = yaml.dump(myDict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.147  Python-3.11.4 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=pose, mode=train, model=D:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\\last.pt, data=D:\\CMC\\DeepVision\\dataset\\multi_class\\dataset.yaml, epochs=200, patience=50, batch=48, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=0, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=True, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=True, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\pose\\train2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    824023  ultralytics.nn.modules.head.Pose             [3, [5, 2], [64, 128, 256]]   \n",
      "YOLOv8n-pose summary: 250 layers, 3083559 parameters, 3083543 gradients\n",
      "\n",
      "Transferred 397/397 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\CMC\\DeepVision\\dataset\\multi_class\\dataset_processed\\labels\\train.cache... 10241 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10241/10241 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\CMC\\DeepVision\\dataset\\multi_class\\dataset_processed\\labels\\val.cache... 1190 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1190/1190 [00:00<?, ?it/s]\n",
      "Plotting labels to runs\\pose\\train2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 63 weight(decay=0.0), 73 weight(decay=0.000375), 72 bias(decay=0.0)\n",
      "Resuming training from D:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\\last.pt from epoch 180 to 200 total epochs\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\pose\\train2\u001b[0m\n",
      "Starting training for 200 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    180/200      7.02G     0.1775    0.01796          0     0.1167     0.7699         72        640: 100%|██████████| 214/214 [04:29<00:00,  1.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:29<00:00,  2.24s/it]\n",
      "                   all       1190       2644      0.995      0.999      0.995      0.993      0.995      0.999      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    181/200      6.99G     0.1789    0.01917          0     0.1178     0.7688         53        640: 100%|██████████| 214/214 [04:26<00:00,  1.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:28<00:00,  2.22s/it]\n",
      "                   all       1190       2644      0.995      0.999      0.995      0.993      0.995      0.999      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    182/200      7.01G     0.1787    0.01836          0     0.1177      0.769         68        640: 100%|██████████| 214/214 [04:27<00:00,  1.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:28<00:00,  2.17s/it]\n",
      "                   all       1190       2644      0.995          1      0.995      0.993      0.995          1      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    183/200      7.02G     0.1765    0.01813          0     0.1163     0.7692         90        640: 100%|██████████| 214/214 [04:28<00:00,  1.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:29<00:00,  2.26s/it]\n",
      "                   all       1190       2644      0.995          1      0.995      0.993      0.995          1      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    184/200      7.01G     0.1755    0.01719          0     0.1156     0.7678         69        640: 100%|██████████| 214/214 [04:24<00:00,  1.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:28<00:00,  2.22s/it]\n",
      "                   all       1190       2644      0.995          1      0.995      0.993      0.995          1      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    185/200      7.01G     0.1766    0.01829          0     0.1159     0.7708         69        640: 100%|██████████| 214/214 [04:28<00:00,  1.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:31<00:00,  2.42s/it]\n",
      "                   all       1190       2644      0.995          1      0.995      0.993      0.995          1      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    186/200      7.01G     0.1765     0.0192          0      0.116     0.7697         64        640: 100%|██████████| 214/214 [05:01<00:00,  1.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:29<00:00,  2.27s/it]\n",
      "                   all       1190       2644      0.995          1      0.995      0.993      0.995          1      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    187/200      7.01G     0.1759     0.0172          0     0.1151      0.769         73        640: 100%|██████████| 214/214 [04:25<00:00,  1.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:28<00:00,  2.22s/it]\n",
      "                   all       1190       2644      0.995          1      0.995      0.993      0.995          1      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    188/200      7.01G     0.1759    0.01812          0     0.1145     0.7695         79        640: 100%|██████████| 214/214 [04:22<00:00,  1.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:27<00:00,  2.12s/it]\n",
      "                   all       1190       2644      0.995          1      0.995      0.993      0.995          1      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    189/200      7.01G     0.1749    0.01751          0     0.1141     0.7679         65        640: 100%|██████████| 214/214 [04:22<00:00,  1.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:27<00:00,  2.10s/it]\n",
      "                   all       1190       2644      0.995      0.999      0.995      0.993      0.995      0.999      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    190/200      7.01G     0.1743    0.01723          0     0.1132     0.7684         84        640: 100%|██████████| 214/214 [04:23<00:00,  1.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:28<00:00,  2.22s/it]\n",
      "                   all       1190       2644      0.995      0.999      0.995      0.993      0.995      0.999      0.995      0.995\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    191/200      6.91G     0.1598    0.01289          0     0.1076     0.7634         35        640: 100%|██████████| 214/214 [04:09<00:00,  1.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:29<00:00,  2.23s/it]\n",
      "                   all       1190       2644      0.995      0.999      0.995      0.993      0.995      0.999      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    192/200       6.9G     0.1574    0.01294          0     0.1052     0.7604         39        640: 100%|██████████| 214/214 [04:08<00:00,  1.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:28<00:00,  2.16s/it]\n",
      "                   all       1190       2644      0.995      0.999      0.995      0.993      0.995      0.999      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    193/200       6.9G     0.1557    0.01226          0     0.1038     0.7614         38        640: 100%|██████████| 214/214 [04:23<00:00,  1.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:28<00:00,  2.21s/it]\n",
      "                   all       1190       2644      0.995      0.999      0.995      0.993      0.995      0.999      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    194/200      6.91G     0.1549    0.01182          0     0.1032     0.7606         43        640: 100%|██████████| 214/214 [04:10<00:00,  1.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:28<00:00,  2.17s/it]\n",
      "                   all       1190       2644      0.996      0.999      0.995      0.993      0.996      0.999      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    195/200      6.91G     0.1539    0.01172          0     0.1029     0.7606         38        640: 100%|██████████| 214/214 [04:17<00:00,  1.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:27<00:00,  2.15s/it]\n",
      "                   all       1190       2644      0.996      0.999      0.995      0.993      0.996      0.999      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    196/200       6.9G     0.1534    0.01158          0     0.1017     0.7611         43        640: 100%|██████████| 214/214 [04:17<00:00,  1.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:29<00:00,  2.28s/it]\n",
      "                   all       1190       2644      0.996      0.999      0.995      0.993      0.996      0.999      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    197/200       6.9G     0.1526    0.01172          0     0.1011     0.7619         33        640: 100%|██████████| 214/214 [14:16<00:00,  4.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [01:28<00:00,  6.78s/it]\n",
      "                   all       1190       2644      0.996      0.999      0.995      0.993      0.996      0.999      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    198/200       6.9G     0.1516    0.01136          0     0.1005     0.7613         38        640: 100%|██████████| 214/214 [14:05<00:00,  3.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [01:41<00:00,  7.82s/it]\n",
      "                   all       1190       2644      0.996      0.999      0.995      0.993      0.996      0.999      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    199/200       6.9G     0.1519     0.0113          0    0.09993      0.761         40        640: 100%|██████████| 214/214 [11:15<00:00,  3.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [02:04<00:00,  9.55s/it]\n",
      "                   all       1190       2644      0.996      0.999      0.995      0.993      0.996      0.999      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    200/200      6.91G     0.1507    0.01138          0    0.09938     0.7589         34        640: 100%|██████████| 214/214 [07:43<00:00,  2.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:33<00:00,  2.55s/it]\n",
      "                   all       1190       2644      0.996      0.999      0.995      0.993      0.996      0.999      0.995      0.995\n",
      "\n",
      "21 epochs completed in 2.270 hours.\n",
      "Optimizer stripped from runs\\pose\\train2\\weights\\last.pt, 6.4MB\n",
      "Optimizer stripped from runs\\pose\\train2\\weights\\best.pt, 6.4MB\n",
      "\n",
      "Validating runs\\pose\\train2\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.147  Python-3.11.4 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "YOLOv8n-pose summary (fused): 187 layers, 3078263 parameters, 0 gradients\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):   0%|          | 0/13 [00:00<?, ?it/s]WARNING  PoseModel has not supported augment inference yet! Now using single-scale inference instead.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):   8%|▊         | 1/13 [00:02<00:29,  2.49s/it]WARNING  PoseModel has not supported augment inference yet! Now using single-scale inference instead.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  15%|█▌        | 2/13 [00:05<00:27,  2.51s/it]WARNING  PoseModel has not supported augment inference yet! Now using single-scale inference instead.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  23%|██▎       | 3/13 [00:07<00:25,  2.51s/it]WARNING  PoseModel has not supported augment inference yet! Now using single-scale inference instead.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  31%|███       | 4/13 [00:10<00:23,  2.58s/it]WARNING  PoseModel has not supported augment inference yet! Now using single-scale inference instead.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  38%|███▊      | 5/13 [00:12<00:20,  2.56s/it]WARNING  PoseModel has not supported augment inference yet! Now using single-scale inference instead.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  46%|████▌     | 6/13 [00:15<00:17,  2.49s/it]WARNING  PoseModel has not supported augment inference yet! Now using single-scale inference instead.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  54%|█████▍    | 7/13 [00:17<00:14,  2.42s/it]WARNING  PoseModel has not supported augment inference yet! Now using single-scale inference instead.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  62%|██████▏   | 8/13 [00:19<00:11,  2.39s/it]WARNING  PoseModel has not supported augment inference yet! Now using single-scale inference instead.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  69%|██████▉   | 9/13 [00:21<00:09,  2.35s/it]WARNING  PoseModel has not supported augment inference yet! Now using single-scale inference instead.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  77%|███████▋  | 10/13 [00:24<00:07,  2.36s/it]WARNING  PoseModel has not supported augment inference yet! Now using single-scale inference instead.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  85%|████████▍ | 11/13 [00:26<00:04,  2.37s/it]WARNING  PoseModel has not supported augment inference yet! Now using single-scale inference instead.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  92%|█████████▏| 12/13 [00:29<00:02,  2.37s/it]WARNING  PoseModel has not supported augment inference yet! Now using single-scale inference instead.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:29<00:00,  2.30s/it]\n",
      "                   all       1190       2644      0.995          1      0.995      0.993      0.995          1      0.995      0.995\n",
      "                    12       1190        769      0.994          1      0.995      0.993      0.994          1      0.995      0.995\n",
      "                    88       1190       1018      0.994          1      0.995      0.993      0.994          1      0.995      0.995\n",
      "                    80       1190        857      0.998      0.999      0.995      0.993      0.998      0.999      0.995      0.995\n",
      "Speed: 0.3ms preprocess, 2.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\pose\\train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# model.train(data=r'D:\\CMC\\DeepVision\\dataset\\multi_class\\dataset.yaml', epochs=200, plots=True, workers=0, batch=48, int8=True, half=True ,\n",
    "#             augment = True)\n",
    "model.train(resume=True, workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = YOLO(r\"C:\\Users\\CMC\\Documents\\openposelibs\\pose\\DeepVision\\models\\kaggle_aruco_multiclass.pt\")\n",
    "# model = YOLO(r\"C:\\Users\\CMC\\Documents\\openposelibs\\pose\\DeepVision\\models\\kaggle_aruco_multiclass.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\CMC\\DeepVision\\dataset\\multi_class\\dataset_processed\\images\\test\\image_4368.png: 384x640 1 12, 1 88, 1 80, 121.4ms\n",
      "Speed: 12.0ms preprocess, 121.4ms inference, 30.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(r\"D:\\CMC\\DeepVision\\dataset\\multi_class\\dataset_processed\\images\\test\\image_4368.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Pintu\\miniconda3\\envs\\py11\\Lib\\site-packages\\ultralytics\\assets\\bus.jpg: 640x480 (no detections), 152.3ms\n",
      "Speed: 4.2ms preprocess, 152.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Ultralytics YOLOv8.0.147  Python-3.11.4 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\CMC\\DeepVision\\dataset\\multi_class\\dataset_processed\\labels\\val.cache... 1190 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1190/1190 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1190/1190 [00:53<00:00, 22.43it/s]\n",
      "                   all       1190       2644      0.996      0.999      0.995      0.994      0.996      0.999      0.995      0.995\n",
      "Speed: 1.4ms preprocess, 11.8ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.147  Python-3.11.4 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'D:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\\last.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 17, 8400) (6.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.0.1+cu118...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  1.1s, saved as 'D:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\\last.torchscript' (12.2 MB)\n",
      "\n",
      "Export complete (1.3s)\n",
      "Results saved to \u001b[1mD:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\u001b[0m\n",
      "Predict:         yolo predict task=pose model=D:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\\last.torchscript imgsz=640 \n",
      "Validate:        yolo val task=pose model=D:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\\last.torchscript imgsz=640 data=None \n",
      "Visualize:       https://netron.app\n",
      "Loading D:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\\last.torchscript for TorchScript inference...\n",
      "\n",
      "image 1/1 C:\\Users\\Pintu\\miniconda3\\envs\\py11\\Lib\\site-packages\\ultralytics\\assets\\bus.jpg: 640x640 (no detections), 62.0ms\n",
      "Speed: 3.8ms preprocess, 62.0ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Ultralytics YOLOv8.0.147  Python-3.11.4 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Loading D:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\\last.torchscript for TorchScript inference...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\CMC\\DeepVision\\dataset\\multi_class\\dataset_processed\\labels\\val.cache... 1190 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1190/1190 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1190/1190 [00:42<00:00, 27.84it/s]\n",
      "                   all       1190       2644      0.996      0.999      0.995      0.994      0.996      0.999      0.995      0.995\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.147  Python-3.11.4 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'D:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\\last.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 17, 8400) (6.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  4.0s, saved as 'D:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\\last.onnx' (12.1 MB)\n",
      "\n",
      "Export complete (4.0s)\n",
      "Results saved to \u001b[1mD:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\u001b[0m\n",
      "Predict:         yolo predict task=pose model=D:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\\last.onnx imgsz=640 \n",
      "Validate:        yolo val task=pose model=D:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\\last.onnx imgsz=640 data=None \n",
      "Visualize:       https://netron.app\n",
      "Loading D:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\\last.onnx for ONNX Runtime inference...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxruntime'] not found, attempting AutoUpdate...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Obtaining dependency information for onnxruntime from https://files.pythonhosted.org/packages/01/ba/58f52bf735687c9dedf662f59ea7e110972481cd4101145c4de528abce35/onnxruntime-1.15.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading onnxruntime-1.15.1-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "     -------------------------------------- 46.0/46.0 kB 567.9 kB/s eta 0:00:00\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Obtaining dependency information for flatbuffers from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: numpy>=1.24.2 in c:\\users\\pintu\\miniconda3\\envs\\py11\\lib\\site-packages (from onnxruntime) (1.25.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\pintu\\miniconda3\\envs\\py11\\lib\\site-packages (from onnxruntime) (23.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\pintu\\miniconda3\\envs\\py11\\lib\\site-packages (from onnxruntime) (4.23.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\pintu\\miniconda3\\envs\\py11\\lib\\site-packages (from onnxruntime) (1.11.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "     -------------------------------------- 86.8/86.8 kB 814.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\pintu\\miniconda3\\envs\\py11\\lib\\site-packages (from sympy->onnxruntime) (1.2.1)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime)\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "     -------------------------------------- 95.2/95.2 kB 903.9 kB/s eta 0:00:00\n",
      "Downloading onnxruntime-1.15.1-cp311-cp311-win_amd64.whl (6.7 MB)\n",
      "   ---------------------------------------- 6.7/6.7 MB 967.9 kB/s eta 0:00:00\n",
      "Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Installing collected packages: pyreadline3, flatbuffers, humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 flatbuffers-23.5.26 humanfriendly-10.0 onnxruntime-1.15.1 pyreadline3-3.4.1\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  34.5s, installed 1 package: ['onnxruntime']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "image 1/1 C:\\Users\\Pintu\\miniconda3\\envs\\py11\\Lib\\site-packages\\ultralytics\\assets\\bus.jpg: 640x640 (no detections), 37.7ms\n",
      "Speed: 4.0ms preprocess, 37.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Ultralytics YOLOv8.0.147  Python-3.11.4 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Loading D:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\\last.onnx for ONNX Runtime inference...\n",
      "Forcing batch=1 square inference (1,3,640,640) for non-PyTorch models\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\CMC\\DeepVision\\dataset\\multi_class\\dataset_processed\\labels\\val.cache... 1190 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1190/1190 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 1190/1190 [02:04<00:00,  9.56it/s]\n",
      "                   all       1190       2644      0.996      0.999      0.995      0.994      0.996      0.999      0.995      0.995\n",
      "Speed: 2.2ms preprocess, 67.9ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "ERROR  Benchmark failure for OpenVINO: inference not supported on GPU\n",
      "Ultralytics YOLOv8.0.147  Python-3.11.4 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'D:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\\last.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 17, 8400) (6.1 MB)\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export failure  0.0s: No module named 'tensorrt'\n",
      "ERROR  Benchmark failure for TensorRT: No module named 'tensorrt'\n",
      "ERROR  Benchmark failure for CoreML: inference not supported on GPU\n",
      "Ultralytics YOLOv8.0.147  Python-3.11.4 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'D:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\\last.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 17, 8400) (6.1 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['tensorflow'] not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  Command 'pip install --no-cache \"tensorflow\"  ' returned non-zero exit status 1.\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export failure  645.6s: No module named 'tensorflow'\n",
      "ERROR  Benchmark failure for TensorFlow SavedModel: No module named 'tensorflow'\n",
      "Ultralytics YOLOv8.0.147  Python-3.11.4 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'D:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\\last.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 17, 8400) (6.1 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['tensorflow'] not found, attempting AutoUpdate...\n"
     ]
    }
   ],
   "source": [
    "benchmark(model=r'D:\\CMC\\DeepVision\\training_notebooks\\runs\\pose\\train2\\weights\\last.pt', data=r'D:\\CMC\\DeepVision\\dataset\\multi_class\\dataset.yaml', imgsz=640, half=False, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
